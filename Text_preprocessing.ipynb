{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf19481-fa8f-450d-8446-f1cafda62dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb401993-9ad1-483f-8823-f079da5e1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86b8f1d-38a0-408a-b066-4c46eee67084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8962349f-42b0-4170-bb06-2498158454fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41f866-5fa0-429d-ae13-ad350eec74cf",
   "metadata": {},
   "source": [
    "# Lower cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7d2d7f-e211-481e-bf11-3a45ec159aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916c645c-d720-48e7-ab11-581c1b875e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f36642-edb8-461d-8626-4694aa7fe224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e34293-32ea-4752-994c-f84992bc61c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f8b07-3b8f-495c-ad3b-68388c78c540",
   "metadata": {},
   "source": [
    "# Remove Html Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9d8e415-ce9e-4225-87ca-6137bfcc4031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35ebf55d-0de6-48ec-94b2-a048a41d0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Original review\n",
    "review = df['review'][3]\n",
    "\n",
    "# Remove HTML tags\n",
    "cleaned_review = re.sub(r'<.*?>', '', review)\n",
    "\n",
    "print(cleaned_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09407f61-44a7-46ab-89b9-e85e69c73812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'<.*?>', '', text)\n",
    "    return text  # return non-string entries unchanged    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7a4ede3-13dc-4362-bf06-b1d5265f13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1642b6a9-f436-4749-b508-8e754b0e355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e56c72-4f24-47fa-929d-a921eab30d1a",
   "metadata": {},
   "source": [
    "# Remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2773c87-b7e0-4d6f-964a-3bb137c6d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'hi hello https://kaggle.com'\n",
    "text2 = 'check this out https://example.com/page'\n",
    "text3 = 'visit us at https://openai.com for more info'\n",
    "text4 = 'download here: https://github.com/user/repo'\n",
    "text5 = 'hellow https://www.kaggle.com/datasets/wikimedia-foundation/wikipedia-structured-contents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fea148e3-889b-498b-9751-4e3e8317bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'https?://\\S+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "defbc481-b7dd-4564-a1b3-387a2c9bace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellow '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679eace-192f-4e18-9e92-88c2878f6cb0",
   "metadata": {},
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c067ae71-b40c-4fcf-9b15-8842d03a96b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fd8f5a3-1883-4f1e-8ff3-59b131a31ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c4e823e-c4dd-4193-905e-ae585658c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b479b225-8fa0-463d-b8dd-1553789c4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'string ., with # punc ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94c0a876-846f-4bb1-8da2-199ae0e98f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string  with  punc '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "216aecea-9d9f-4799-a6ee-98640975ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string  with  punc \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_pun(text))\n",
    "time1 = time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3305700-1bf2-428a-a66a-a6f0c66ebebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast approach\n",
    "def remove_punch1(text):\n",
    "    return text.translate( str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa913fb0-92fd-4550-a932-fc40940a1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string  with  punc \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punch1(text))\n",
    "time2 = time.time() - start\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee32fe8-de6b-4715-b2f2-e656e5233958",
   "metadata": {},
   "source": [
    "# Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a9fc9d7-af0e-41c1-a113-a39fa4a7ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek you\",\n",
    "    \"ILU\": \"I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laughing My A** Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A**\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA?\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A** Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your Sex and Age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That Feeling When\",\n",
    "    \"MFW\": \"My Face When\",\n",
    "    \"MRW\": \"My Reaction When\",\n",
    "    \"IFYP\": \"I Feel Your Pain\",\n",
    "    \"TNTL\": \"Trying Not To Laugh\",\n",
    "    \"JK\": \"Just Kidding\",\n",
    "    \"IDC\": \"I Donâ€™t Care\",\n",
    "    \"ILY\": \"I Love You\",\n",
    "    \"IMU\": \"I Miss You\",\n",
    "    \"ADIH\": \"Another Day In Hell\",\n",
    "    \"ZZZ\": \"Sleeping, Bored, Tired\",\n",
    "    \"WYWH\": \"Wish You Were Here\",\n",
    "    \"TIME\": \"Tears In My Eyes\",\n",
    "    \"BAE\": \"Before Anyone Else\",\n",
    "    \"FIMH\": \"Forever In My Heart\",\n",
    "    \"BSAAW\": \"Big Smile And A Wink\",\n",
    "    \"BWL\": \"Bursting With Laughter\",\n",
    "    \"BFF\": \"Best Friends Forever\",\n",
    "    \"CSL\": \"Canâ€™t Stop Laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a411fa40-d1d9-49a7-9579-971d97f38396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Night'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words['GN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a883ff81-4aaf-4d92-8d05-7ae3431a47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([chat_words.get(word.upper(), word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d998a85e-eece-48f5-b022-738b45f3d3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Night rushi'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation('gn rushi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7fbe3-d796-4a17-a17b-5e2f75d7af58",
   "metadata": {},
   "source": [
    "# Spelling Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0995d47d-8e14-40a5-a93e-4589afba90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96a41b89-ba2e-4255-96b3-29bbc4e89ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain condition during seal'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = \"ccertain condtion during sveal\"\n",
    "TextBlb = TextBlob(incorrect_text)\n",
    "TextBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd37c8-c112-463a-b7e4-9802536c6e6e",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbfd7bde-d152-4289-ab92-a0e565ab8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not removing in pos tagging\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd96bf43-67d6-4774-9df4-16b213464392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7417fc36-9a49-44f8-8a5f-8c1e9b05edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d23d7ab-7399-4c6d-9238-6d74b4c22120",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize by splitting on whitespace and punctuation (simple approach)\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1420635e-136d-453c-8722-f6e3c3353dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample sentence showing stop words filtration\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "print(remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9200793e-3b97-499a-b949-487937254592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e95f6bd2-493c-43fd-a795-a9899ec91062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake thinks zombie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically family little boy jake thinks zombie...  negative\n",
       "4  petter mattei love time money visually stunnin...  positive"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69352f06-5d0a-4540-94a7-0f82074b022b",
   "metadata": {},
   "source": [
    "# Handling emojies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac4e6e-c8f3-4518-8f85-3a3f9ba73363",
   "metadata": {},
   "source": [
    "## 1 remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7aff518e-3410-4555-a54c-dc6bd2afd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "        \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd7b03d9-a36b-463a-a80d-290b2f4134dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello ! This is fun \n"
     ]
    }
   ],
   "source": [
    "text = \"Hello ðŸ‘‹ðŸŒ! This is fun ðŸ˜„ðŸ‘\"\n",
    "print(remove_emojis(text))\n",
    "# Output: Hello ! This is fun "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07717367-100e-4f93-b197-9a4eb7c1f40a",
   "metadata": {},
   "source": [
    "## 2 replace like happy, sad, cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dc7f042-6272-4036-b1ee-6e7551fd0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is  :fire::fire::fire:!\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('python is  ðŸ”¥ðŸ”¥ðŸ”¥!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c042af-fbca-4069-ac45-9d6bca1f7b3a",
   "metadata": {},
   "source": [
    "# Tokenizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c7796-1c0b-45b2-ae97-a3efb8ab48d1",
   "metadata": {},
   "source": [
    "## 1 Using split finction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0629d56f-45a1-4878-9355-f471ed8877f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'gujrat']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1 = \"I am going to gujrat\"\n",
    "sen1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "309abb54-a2d8-483d-82c2-6d78b77ce3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to gujrat', ' I am going to USA', ' I am going to PA']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1 = \"I am going to gujrat. I am going to USA. I am going to PA\"\n",
    "sen1.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28e707a3-27e4-48d0-a078-ce5fa5e3d711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'gujrat!']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem with split function\n",
    "sen1 = \"I am going to gujrat!\"\n",
    "sen1.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a0364-769f-48e9-82c8-2ad3484a87d5",
   "metadata": {},
   "source": [
    "## 2 Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3706f74-dffe-4d5a-b9e2-d353afaecbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sen3 = \"I am going to delhi!\"\n",
    "tokens = re.findall(r\"[\\w']+\", sen3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "791f3458-43ba-402e-b849-3204bf93bdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipiscing', 'elit', 'sed', 'do', 'eiusmod', 'tempor', '']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"lorem ipsum dolor sit amet.\n",
    "consectetur adipiscing elit...\n",
    "sed do eiusmod tempor!\"\"\"\n",
    "\n",
    "pattern = re.compile(r\"[^\\w']+\")\n",
    "tokens = pattern.split(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0eac08-5456-42d6-8041-e601ff0a8bd5",
   "metadata": {},
   "source": [
    "## 3 Nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f457dc58-7201-42ab-b492-d77b32b5201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1eeb4799-707c-4542-a67d-7e65141b0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f305f3f6-39c1-439e-8260-2d62b012eba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"I am going to visit delhi!\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "75eaded5-8b88-4f34-84c2-a81750ad2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize use for sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "773555ec-8b08-4174-9aad-f0df2f299cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = \"I have ph.d in Ai\"\n",
    "s3 = \"we're here to help! mail us at rv@gmail.com\"\n",
    "s4 = \"A 5km ride cost $10.50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9520f8f2-d500-446e-bd7b-c173c6cb6103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'ph.d', 'in', 'Ai']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b18f917c-29ea-4008-a433-bab952a9f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'rv',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "72bcd0ad-61c3-4858-8e04-d9e7450cc256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd0b4a-95d2-45fc-8155-5cc6ce15919d",
   "metadata": {},
   "source": [
    "## 4 spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3dc8e6a-0336-4203-945a-4086a7cc790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working now conflict with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "003a5c4a-3ae1-4bdf-bc27-216fd10d1286",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "96379c46-16ec-44e5-abfb-06c8eb9ada2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: spacy 3.8.7\n",
      "Uninstalling spacy-3.8.7:\n",
      "  Successfully uninstalled spacy-3.8.7\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall -y spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb1c54-0d62-498e-9324-7ed96a721d0f",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e0e0f-5ed3-4f19-96c5-820c12d00a0b",
   "metadata": {},
   "source": [
    "In grammar, **inflection** refers to the change in the form of a word to express different grammatical features such as:\n",
    "\n",
    "* **Tense** (past, present, future)\n",
    "* **Number** (singular, plural)\n",
    "* **Gender** (masculine, feminine, neuter in some languages)\n",
    "* **Case** (like nominative, accusative in Latin/German)\n",
    "* **Person** (I, you, he/she/it, we, they)\n",
    "* **Mood** or **Voice** (in verbs)\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Examples in English:\n",
    "\n",
    "#### 1. **Verbs (Tense and Person)**\n",
    "\n",
    "* **walk** â†’ **walked** (past tense)\n",
    "* **run** â†’ **runs**, **ran**, **running**\n",
    "\n",
    "#### 2. **Nouns (Number)**\n",
    "\n",
    "* **cat** â†’ **cats** (plural)\n",
    "* **child** â†’ **children**\n",
    "\n",
    "#### 3. **Adjectives (Comparative/Superlative)**\n",
    "\n",
    "* **fast** â†’ **faster**, **fastest**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12745c12-c7ca-4bd8-9750-5e89f1689177",
   "metadata": {},
   "source": [
    "### Stemming is the process of reducing inflection a word to its root or base form by removing suffixes or prefixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1c2aa976-98fd-46de-85cf-ffa8b69c8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "33bf1049-4704-4436-b759-a8932d1087d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "33c52085-9b90-4182-b053-1d946565f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run jump easili\n"
     ]
    }
   ],
   "source": [
    "print(stem_words(\"running jumps easily\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e671c-ad27-4b83-9e04-8c7b03c0171b",
   "metadata": {},
   "source": [
    "### Problem in stemming\n",
    "##### easily == easili\n",
    "##### movie == movi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567a1f4-8fb6-464d-81ef-4a5b3407c44d",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Lemmatization is the process of reducing a word to its base or dictionary form (lemma), using vocabulary and morphological analysis.\n",
    "Unlike stemming, it returns real words (e.g., \"running\" â†’ \"run\", \"better\" â†’ \"good\").\n",
    "\n",
    "In a real-world project, if we need to show results so we use lemmatization \n",
    "It is slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aafa6016-03d2-4fcd-9e9b-b328704dd695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\satha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\satha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Make sure the WordNet data is available\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bd38b193-21a6-457e-88c0-dbcc38bde5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The leaf are falling from the tree\n"
     ]
    }
   ],
   "source": [
    "print(lemmatize_text(\"The leaves are falling from the trees\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1679d-7390-4b71-9194-e3adc7155a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
